[2023-02-10T22:30:12.941+0200] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: test_process_sales.extract_data_from_api scheduled__2023-01-09T20:05:00+00:00 [queued]>
[2023-02-10T22:30:12.947+0200] {taskinstance.py:1171} INFO - Dependencies all met for <TaskInstance: test_process_sales.extract_data_from_api scheduled__2023-01-09T20:05:00+00:00 [queued]>
[2023-02-10T22:30:12.947+0200] {taskinstance.py:1368} INFO - 
--------------------------------------------------------------------------------
[2023-02-10T22:30:12.947+0200] {taskinstance.py:1369} INFO - Starting attempt 3 of 4
[2023-02-10T22:30:12.947+0200] {taskinstance.py:1370} INFO - 
--------------------------------------------------------------------------------
[2023-02-10T22:30:12.953+0200] {taskinstance.py:1389} INFO - Executing <Task(PythonOperator): extract_data_from_api> on 2023-01-09 20:05:00+00:00
[2023-02-10T22:30:12.957+0200] {standard_task_runner.py:52} INFO - Started process 9909 to run task
[2023-02-10T22:30:12.961+0200] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'test_process_sales', 'extract_data_from_api', 'scheduled__2023-01-09T20:05:00+00:00', '--job-id', '301', '--raw', '--subdir', 'DAGS_FOLDER/process_sales/mainS.py', '--cfg-path', '/var/folders/1g/4w5x68gx3d92wgygb97jqbd40000gp/T/tmp6uxgvu0u', '--error-file', '/var/folders/1g/4w5x68gx3d92wgygb97jqbd40000gp/T/tmpsrc4y4di']
[2023-02-10T22:30:12.962+0200] {standard_task_runner.py:80} INFO - Job 301: Subtask extract_data_from_api
[2023-02-10T22:30:12.991+0200] {task_command.py:371} INFO - Running <TaskInstance: test_process_sales.extract_data_from_api scheduled__2023-01-09T20:05:00+00:00 [running]> on host admins-MacBook-Air-2.local
[2023-02-10T22:30:13.017+0200] {taskinstance.py:1581} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=admin@example.com
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=test_process_sales
AIRFLOW_CTX_TASK_ID=extract_data_from_api
AIRFLOW_CTX_EXECUTION_DATE=2023-01-09T20:05:00+00:00
AIRFLOW_CTX_TRY_NUMBER=3
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2023-01-09T20:05:00+00:00
[2023-02-10T22:30:13.018+0200] {extract_data_from_api.py:40} INFO - Your custom error1
[2023-02-10T22:30:13.018+0200] {extract_data_from_api.py:41} INFO - Your custom error2
[2023-02-10T22:30:13.019+0200] {logging_mixin.py:115} INFO - Your custom error3
[2023-02-10T22:30:13.019+0200] {taskinstance.py:1902} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/Users/v.lytvyniuk/Documents/библиотечка/DE online1/git/de_7/lesson_07/airflow_env/lib/python3.8/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/Users/v.lytvyniuk/Documents/библиотечка/DE online1/git/de_7/lesson_07/airflow_env/lib/python3.8/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/Users/v.lytvyniuk/Documents/библиотечка/DE online1/git/de_7/lesson_07/dags/process_sales/extract_data_from_api.py", line 43, in main
    pprint('Your custom error4')
TypeError: 'module' object is not callable
[2023-02-10T22:30:13.021+0200] {taskinstance.py:1407} INFO - Marking task as UP_FOR_RETRY. dag_id=test_process_sales, task_id=extract_data_from_api, execution_date=20230109T200500, start_date=20230210T203012, end_date=20230210T203013
[2023-02-10T22:30:13.026+0200] {standard_task_runner.py:92} ERROR - Failed to execute job 301 for task extract_data_from_api ('module' object is not callable; 9909)
[2023-02-10T22:30:13.061+0200] {local_task_job.py:156} INFO - Task exited with return code 1
[2023-02-10T22:30:13.072+0200] {local_task_job.py:279} INFO - 0 downstream tasks scheduled from follow-on schedule check
